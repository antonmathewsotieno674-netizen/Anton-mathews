
import { GoogleGenAI, Content, Part } from "@google/genai";
import { 
  GEMINI_MODEL_STANDARD, 
  GEMINI_MODEL_FAST, 
  GEMINI_MODEL_THINKING, 
  GEMINI_MODEL_MAPS,
  GEMINI_MODEL_VISION, 
  SYSTEM_INSTRUCTION 
} from "../constants";
import { UploadedFile, Message, ActionItem, ModelMode, GroundingLink } from "../types";

// Initialize the client
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

/**
 * Generates an abstract AI background wallpaper using Imagen.
 * Prioritizes Imagen 4.0, falls back to Gemini 2.5 Flash Image.
 */
export const generateWallpaper = async (): Promise<string> => {
  // Updated prompt for a fresher, high-tech look
  const prompt = 'Futuristic abstract data landscape, flowing streams of glowing neural nodes, deep indigo and cybernetic blue gradients, subtle glass morphism effects, 8k resolution, ultra-detailed, cinematic lighting, sleek modern UI background, abstract intelligence';

  try {
    // Attempt with Imagen 4.0 model as requested
    console.log("Attempting to generate wallpaper with imagen-4.0-generate-001...");
    const response = await ai.models.generateImages({
      model: 'imagen-4.0-generate-001',
      prompt: prompt,
      config: {
        numberOfImages: 1,
        outputMimeType: 'image/jpeg',
        aspectRatio: '16:9',
      },
    });

    if (response.generatedImages?.[0]?.image?.imageBytes) {
       const base64String = response.generatedImages[0].image.imageBytes;
       return `data:image/jpeg;base64,${base64String}`;
    }
    throw new Error("No image generated by the Imagen model.");
  } catch (error) {
    console.warn("Imagen generation failed, falling back to Gemini Flash Image:", error);
    
    // Fallback to Gemini 2.5 Flash Image if Imagen is unavailable/fails
    try {
        const fallbackResponse = await ai.models.generateContent({
          model: 'gemini-2.5-flash-image',
          contents: {
            parts: [
              { text: prompt },
            ],
          },
          config: {
            imageConfig: {
              aspectRatio: '16:9',
            }
          },
        });
    
        for (const part of fallbackResponse.candidates?.[0]?.content?.parts || []) {
          if (part.inlineData) {
            return `data:image/jpeg;base64,${part.inlineData.data}`;
          }
        }
    } catch (fallbackError) {
        console.error("Fallback generation failed:", fallbackError);
    }

    throw new Error("Failed to generate wallpaper. Please try again.");
  }
};

/**
 * Extracts text from an image file using Gemini Vision capabilities (OCR).
 */
export const performOCR = async (file: File): Promise<string> => {
  try {
    const base64Data = await new Promise<string>((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsDataURL(file);
      reader.onload = () => resolve(reader.result as string);
      reader.onerror = reject;
    });

    const base64String = base64Data.split(',')[1];

    const response = await ai.models.generateContent({
      model: GEMINI_MODEL_VISION,
      contents: [
        {
          role: 'user',
          parts: [
            {
              inlineData: {
                mimeType: file.type,
                data: base64String
              }
            },
            { text: "Please transcribe all the text found in this image exactly as it appears. If the image contains handwriting, try your best to read it. If there is no text, describe the image in detail suitable for study notes. Output only the extracted text or description." }
          ]
        }
      ]
    });

    return response.text || "No text could be extracted from this image.";
  } catch (error) {
    console.error("OCR Error:", error);
    throw new Error("Failed to extract text from image.");
  }
};

/**
 * Generates response based on selected mode.
 */
export const generateResponse = async (
  history: Message[],
  currentQuery: string,
  file: UploadedFile | null,
  mode: ModelMode = 'standard',
  location?: { lat: number; lng: number }
): Promise<{ text: string, groundingLinks?: GroundingLink[] }> => {
  try {
    let modelName = GEMINI_MODEL_STANDARD;
    let config: any = {
      systemInstruction: SYSTEM_INSTRUCTION,
    };

    // Configure based on Mode
    switch (mode) {
      case 'fast':
        modelName = GEMINI_MODEL_FAST;
        break;
      case 'thinking':
        modelName = GEMINI_MODEL_THINKING;
        config = {
          ...config,
          thinkingConfig: { thinkingBudget: 32768 } // Max budget for pro
        };
        break;
      case 'maps':
        modelName = GEMINI_MODEL_MAPS;
        config = {
          ...config,
          tools: [{ googleMaps: {} }]
        };
        // Add location if available
        if (location) {
          config.toolConfig = {
            retrievalConfig: {
              latLng: {
                latitude: location.lat,
                longitude: location.lng
              }
            }
          };
        }
        break;
      default:
        modelName = GEMINI_MODEL_STANDARD;
    }

    // Construct content
    let parts: Part[] = [{ text: currentQuery }];
    let contents: Content[] = [];

    const previousHistory: Content[] = history.map(msg => ({
      role: msg.role,
      parts: [{ text: msg.text }]
    }));

    contents = [...previousHistory];

    if (file) {
      if (file.category === 'image' && !file.originalImage) {
        const base64Data = file.content.split(',')[1]; 
        parts.unshift({
          inlineData: {
            mimeType: file.type,
            data: base64Data
          }
        });
        parts.unshift({ text: "Here is the image file I uploaded for reference: " });
      } else {
        parts.unshift({ text: `\n\n--- BEGIN UPLOADED NOTE CONTENT (${file.name}) ---\n${file.content}\n--- END NOTE CONTENT ---\n\nBased on the note above: ` });
      }
    }

    contents.push({ role: 'user', parts: parts });

    const response = await ai.models.generateContent({
      model: modelName,
      contents: contents,
      config: config
    });

    let finalText = response.text || "I couldn't generate a response based on that input.";
    let groundingLinks: GroundingLink[] = [];

    // Extract Maps Grounding Links
    if (mode === 'maps' && response.candidates?.[0]?.groundingMetadata?.groundingChunks) {
      response.candidates[0].groundingMetadata.groundingChunks.forEach((chunk: any) => {
        if (chunk.web?.uri && chunk.web?.title) {
          groundingLinks.push({ title: chunk.web.title, uri: chunk.web.uri });
        }
      });
    }

    return { text: finalText, groundingLinks };

  } catch (error) {
    console.error("Gemini API Error:", error);
    throw new Error("Failed to get response from AI. Please try again.");
  }
};

/**
 * Extracts actionable tasks.
 */
export const extractTasks = async (
  file: UploadedFile | null,
  history: Message[]
): Promise<ActionItem[]> => {
  try {
    const model = GEMINI_MODEL_STANDARD;
    
    let contextText = "";
    if (file && file.category === 'text') {
      contextText += `Note Content: ${file.content.substring(0, 10000)}... (truncated)\n`;
    }
    
    const chatHistory = history.map(m => `${m.role}: ${m.text}`).join('\n');
    contextText += `\nChat History:\n${chatHistory}`;

    const prompt = `Analyze the provided notes and chat history. Identify actionable tasks, study goals, or to-do items. 
    Return a JSON object with a key 'tasks' containing an array of strings. 
    If no clear tasks exist, suggest 3-5 relevant study tasks based on the content.
    Example JSON: { "tasks": ["Review chapter 1", "Practice calculus problems"] }`;

    const response = await ai.models.generateContent({
      model: model,
      contents: [
        { role: 'user', parts: [{ text: contextText }, { text: prompt }] }
      ],
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) return [];

    try {
      const parsed = JSON.parse(text);
      if (parsed.tasks && Array.isArray(parsed.tasks)) {
        return parsed.tasks.map((task: string, index: number) => ({
          id: `task_${Date.now()}_${index}`,
          content: task,
          isCompleted: false
        }));
      }
    } catch (e) {
      console.warn("Failed to parse JSON task response", e);
    }
    
    return [];

  } catch (error) {
    console.error("Task Extraction Error:", error);
    throw new Error("Failed to extract tasks.");
  }
};
